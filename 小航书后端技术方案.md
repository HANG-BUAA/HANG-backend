# 小航书后端技术方案

本文档为小航书项目第一期后端技术报告，介绍了整个后端服务架构，技术选型，实现思路以及部分重点问题的处理方案。

## 系统架构

本系统后端采用**微服务架构**，主要由以下11个服务构成：

1. 主后端服务`HANG-backend`: 对客户端提供**API**，并向下串联起各服务；
2. 搜索微服务`HANG-search-client`: 负责系统中搜索任务，向上与主服务之间通过`rabbitmq`异步地同步数据，并提供相应查询接口；向下与`elasticsearch`交互，执行**全文本搜索功能**；
3. 日志微服务`HANG-log-processor`: 负责系统**日志记录**，同样通过`rabbitmq`接受各服务的日志记录，并对主后端服务提供查询接口；向下与`mongodb`数据库交互，记录日志信息；
4. 爬虫微服务`HANG-scraper-service`: 负责定时抓取互联网数据，并存储至`mongodb`中，对外提供日志查询相应接口；
5. 数据库服务`mysql`: 用作系统的**主关系数据库**，记录主后端服务相应的记录；
6. 数据库服务`redis`: 用于存储系统中**临时数据**，以及**数据缓存**；
7. 数据库服务`mongodb`: 用于存储系统中**非结构化以及时限数据**，并执行**聚合查询**功能；
8. 消息队列服务`rabbitmq`: 用于系统中**异步化同步操作**，以及对**分布式架构负载均衡**的开放考虑；
9. 搜索引擎服务`elasticsearch`: 用于存储系统检索的数据信息，执行**全文本搜索**；
10. AIGC模型部署服务`ComfyUI`: 用于部署`flux`模型，支持系统中**文生图**相关功能；
11. 模型调度服务`ComfyUI-server`: 用于**工厂化部署**ComfyUI工作流，**调度上下层服务**，并执行**web hook**；
12. smtp服务：目前使用的163邮箱的服务，用于给邮箱**发送验证码**.

各服务之间的关系如下图所示：

![](./images/backend.png)

其中 `ComfyUI-server`单独做成了一个项目，目前已开源在[github](https://github.com/Poseidon-fan/ComfyUI-server)开源，其架构如下：
![](./images/comfyui.png)
## 技术选型

| 技术选型      | 官方文档/链接                                                | 用途                                                         |                           选型考量                           |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | :----------------------------------------------------------: |
| golang语言    | [https://go.dev/](https://go.dev/)                           | 主后端语言                                                   | go语言在主流后端语言中**效率当属最高**，纯编译设计以及协程的特性使得其运行效率远高于JAVA，python等语言实现的后端框架。 |
| gin框架       | [https://github.com/gin-gonic/gin](https://github.com/gin-gonic/gin) | 主后端框架                                                   | gin框架是go语言实现的应用级框架中**效率最高**，对并发支持的最好的框架，据官方评测单机最高可承受3.1W qps并发，且架构优良，功能完善，**对开发者非常友好**。 |
| gorm框架      | [https://gorm.io/zh_CN/docs/index.html](https://gorm.io/zh_CN/docs/index.html) | 主后端的ORM框架                                              | go语言中最完善的ORM框架，提供，包装了丰富的sql相关接口，**增加开发效率**。 |
| rabbitmq      | [https://www.rabbitmq.com/](https://www.rabbitmq.com/)       | 用于系统异步消息队列，同步各服务间信息。生产者为主后端，消费者为搜索微服务与日志微服务 | 全世界中最广泛使用的消息队列，**提供了多语言sdk**（系统中用到了go语言的amtp以及python的异步版本aio_pika）。相比kafka，socketmq等同类消息队列，rabbitmq更**轻量**，但**功能完善**，我们系统中主要使用了direct路由机制。该设计使得后面扩展为分布式架构时重构成本大大减小。 |
| mysql         | [https://www.mysql.com/cn/](https://www.mysql.com/cn/)       | 用作系统主关系数据库                                         | 世界上最流行的开源关系数据库之一，文档齐全，**各语言及框架支持完备**，性能也不错。 |
| redis         | [https://redis.io/](https://redis.io/)                       | 用于存储验证码等临时信息，以及数据缓存                       | 对于**验证码**这一类的数据而言，入库非常不合适，因为5min过期后就再也没用了，故而存储在内存里非常合适；同时系统中近期的帖子等信息会被频繁地访问，将部分**数据缓存**到内存中会大大减小系统查询开销；同时，目前系统中部分的锁机制实现方式是应用程序级别的锁，之后迁移到分布式架构时可能会使用redis实现**分布式锁** |
| mongodb       | [https://www.mongodb.com/zh-cn](https://www.mongodb.com/zh-cn) | 用于存储日志，爬虫所得数据等非结构化的，有存储时限的数据，并执行相应的聚合查询 | 系统中不同类比的日志信息，以及爬虫所得信息**嵌套层次太深**，常规的关系数据库受到第一范式的显示，处理起来相当吃力，mongo的**bson格式**存储使得系统系统可以轻松地处理这些信息；并且日志中部分类别，如访问日志等，一般设有**存储时限**，mongo的**ttl字段**的设定可以在系统层级处理这些，而无需应用程序的协调 |
| elasticsearch | [https://www.elastic.co/cn/elasticsearch](https://www.elastic.co/cn/elasticsearch) | 用作系统的分布式搜索引擎，执行全文本搜索功能                 | 系统需求分析时我们明确了树洞系统最核心的功能是对外提供精准的搜索能力，elastcearch作为上一代工业互联网的杰出产品，在稳定性以及效率上有着巨大的优势，能够轻松地执行**全文本搜索**的任务，并且其search_after功能的设定与系统**游标分页**功能兼容 |
| fastapi       | [https://fastapi.tiangolo.com/#interactive-api-docs-upgrade](https://fastapi.tiangolo.com/#interactive-api-docs-upgrade) | 用作搜索微服务以及日志微服务的http服务器                     | 由于其异步协程的特性，使得架构在一定程度上打破了python语言全局锁的限制，成为了python语言实现出的**性能最强**的后端框架，官方说法和go（编译，协程特性）语言以及node.js（JIT特性）的效率相当；且抽象层次非常高，**对开发者非常方便**，尤其适合用作微服务架构 |
| ComfyUI       | [https://github.com/comfyanonymous/ComfyUI](https://github.com/comfyanonymous/ComfyUI) | 用于部署flux模型相关工作流                                   | 当今世界AIGC领域**最流行的**Stable Diffusion系列模型的部署框架，其工作流设定以及内置的异步队列还有基础api端口还有节点式设计使得其非常**方便扩展** |

以上为系统中主要的技术选型，对于一些语言第三方sdk等不一一列举，可以参考系统源代码。

## 数据库表结构设计

略（数据库作业）

## 重点技术方案

### 1. 假名分配

由于本系统支持在一个帖子下匿名或实名发言，使得为用户在相应的帖子下发表评论时分配假名成为系统的关键功能，对于该功能，我在初期调研清华，北大等学校树洞论坛时发现大家的设定基本相同，如下：

1. 对于同一个帖子（post）而言，其下面的匿名发表评论的用户的假名之间不同，但统一用户发表多条评论时需使用同一假名；
2. 系统中假名的顺序是写死的，比如在同一帖子下，第一个匿名评论的用户叫Bob，第二个叫Alice...

我们认为该设定合理，不难抽象成如下的问题：

1. 对于相同的`post_id`，不同的`user_id`之间分配的假名应当不同；
2. 对于相同的`post_id`和`user_id`，应当只有用户第一次发表时才分配假名，后面再发言时使用相同的假名。

我参考了[清华大学第三代树洞的源码](https://github.com/treehollow/treehollow-backend)后，发现它们只是简单地在系统中为假名打表，然后用户发表评论时检测是否在同样的帖子下发表过评论，如果没有就分配一个假名。

但是这样的设计时存在bug的：在高并发的场景下，如果两个用户同时第一次地在某个帖子下发表评论，由于此处没有执行数据库的插入操作，会导致查询出的帖子下的匿名数是相同的，进而导致错误地分配了假名的问题。

为了解决上述隐患，我曾考虑过如下的解决思路：

- 简单线性映射：将`user_id + post_id`当作用户在特定帖子下在假名列表中的索引。这样哪怕帖子还没有出现，哪怕用户还没有在帖子下匿名发言，其假名已经是确定的了，这样会导致两个问题：
    1. 假名序列无限增长：随着系统中的用户数以及帖子数的增长，其索引值也会增加，当索引溢出时系统将出现无法挽回的bug
    2. 用户推断导致数据泄露：用户会发现自己在上一个帖子第二个匿名评论和下一个帖子第一个评论分配的假名是一样的，并且用户是知道自己的`user_id`以及相应的`post_id`的，不难推断出系统的设定，进而导致匿名系统泄露。
- 哈希加密：对`user_id`以及`post_id`联合进行哈希映射，映射到匿名集合索引。这样由于系统预先打表的数据长度有限，哈希映射的值域有限，导致不得不考虑哈希冲突的问题，并且由于映射规则恒定，一旦出现了哈希冲突，会导致系统无法进行扩展，限制太多。

最后的处理方案如下：

结合**数据库事务**以及**悲观锁机制**，将用户的分配假名整体的sql操作封装为数据库事务进行提交，同时利用go语言的mutex锁对`user_id`和`post_id`加锁，`post_id`为密钥，使得不同用户在同一个帖子下分配假名的操作同步执行，保证了数据正确性的同时，尽最大可能保证了并发效率（没有对整个service加密）。

### 2. 评论层级嵌套

经过调研，目前主流的论坛系统，如：[知乎](https://www.zhihu.com/)，[CSDN](https://www.csdn.net/)，[bilibili](https://www.bilibili.com/)等均采用了二级评论机制：

一个帖子中，发表评论的人为洞主，直接回复该条评论的为1级评论，而回复1级评论以及2级评论的评论都称为2级评论（递归嵌套），为实现系统外模式能够区分出一二级评论，我曾经考虑过这两种处理方案：

- 一二级评论单独拆成两张表：好处是一目了然，缺点是应用程序里管理较为麻烦，需要协调两张表对外提供统一的接口，并且该模式天然地无法支持多级评论的扩展的需求；
- 不区分一二级评论记录，只记录当前的评论回复的帖子/评论的id，查询时利用数据库的**递归查询**来实现。虽然现代的数据库产品一般都支持了递归查询的功能，但是毕竟对性能有较大的损失。

最后的处理方案如下：

对于一条评论，记录如下字段：

- `post_id`，表示这是哪个帖子下的评论。

- `reply_comment_id`，当该字段为0时表示这是对帖子的直接的回复，否则表示回复的评论的id（以此区分一二级评论）。
- `reply_root_comment_id`，根评论的id，当为一级评论时改字段为0，否则为根评论的id，以此进行评论的查询。

### 3. 全文本搜索功能与微服务架构

由于搜索是本系统的核心功能，并且可能成为系统负载压力最大的地方，也可能在以后做扩展，所以单独部署了一个服务去做搜索相关的业务处理。

技术调研时发现搜索功能主要有三种实现途径：

1. 关系数据库原生的全文本搜索：清华的源码里用的是`mysql`自带的，`postgres`也支持增加一个tsv字段来全文搜索。但是关系数据库自带的fulltext search其实很弱，重点体现在分词器上——`mysql`效果很差，`postgres`甚至对中文这种不靠空格分词的语言没有支持。[postgres的官方文档链接](https://www.postgresql.org/docs/current/textsearch.html)
2. Elastic search：上一代工业互联网的产品，用来做全文搜索算是最佳选择了，最终本期的选型也是这个。
3. Llama index结合向量数据库做语义搜索，比较新的技术，后面会考虑迁移到这上面来。

对于同步`es`的数据，其实完全没有必要同步——用户是不可见的。所以使用了`rabbitmq`做中间消息队列，异步地将数据同步到`rabbitmq`里，再由`rabbitmq`同步到`es`中。这里我们的主后端（go端）是队列的生产者，搜索端（python端）是其消费者，同时也提供搜索相关的服务。所以python端有两个作用：

1. 利用`aio_pika`连接`rabbitmq`，做队列的消费者
2. 利用`fastapi`做路由导航，对主后端提供搜索服务

### 4. 验证码存储

由于验证码信息5min后就会过期，且在系统中再没用任何用处，故而直接入库是对系统资源巨大的浪费，这里考虑使用`redis`将其存储到了内存里，设置了过期时间，完美地解决了时效的问题。

### 5. 日志存储

由于系统中日志信息类别多样，且嵌套层数过深，比如系统访问日志的格式如下：

```json
{
    "_id": "6754522730b0b0c49e851125",
    "type": 1,
    "level": 2,
    "source": 1,
    "timestamp": 1733579303,
    "request": {
        "method": "GET",
        "url": "/api/v1/posts?page_size=6",
        "headers": {
            "Accept-Encoding": "gzip",
            "Authorization": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJJRCI6MSwiTmFtZSI6IjIyMzcxNDI2Iiwic3ViIjoiVG9rZW4iLCJleHAiOjE3MzM1Nzk1MDQsImlhdCI6MTczMzU3NzcwNH0.x7LL2bDzLOiipfZkavG18IoI8DLfX-lO3Wks5ElrRpc",
            "Connection": "Keep-Alive",
            "Content-Type": "application/json",
            "User-Agent": "okhttp/4.11.0"
        },
        "client_ip": "124.127.236.65",
        "query_params": {
            "page_size": "6"
        }
    },
    "response": {
        "status_code": 200
    },
    "user": {
        "user_id": 1,
        "role": 1
    },
    "execution_time": 23,
    "request_id": "123",
    "expire_at": "2024-12-14T21:48:23.952000"
}
```

关系数据库受到第一范式的限制，处理这种结构的数据开销巨大。

并且由于不同级别的日志需要保存的时间是不同的，对于访问日志等低级别的日志信息可能15天就可以清理了，而对于高等级的需要延长时效甚至永久存储。在应用程序里实现这一点是不太方便的，更倾向于在系统级别就实现上述特性。

同时，对于日志信息的查询是系统设计的重中之重，要支持多维度的查询，这一点在关系数据库上实现的话需要多表连接，性能开销巨大。

而`mongodb`是这需求的完美解决方案，其优点体现在如下几点：

1. 本身基于`bson`格式存储，完全非结构化，能够适配多种类别的日志统一管理；
2. 其支持通过设置 TTL 使集合中的数据过期（见[https://www.mongodb.com/zh-cn/docs/manual/tutorial/expire-data/](https://www.bilibili.com/)），可以灵活且十分方便地处理这一需求；
3. 其强大的聚合查询功能使得查询更方便，灵活，高效。

故而最后选用`mongodb`存储系统的日志信息。而日志传输同样依靠`rabbitmq`实现，对不同级别的日志发送到同一交换机的不同路由键上，使得可以分开设定 TTL

### 6. 游标分页与上层接口统一化

对于系统中帖子，评论这类资源，采用分页的方式处理是必然的，但如何分页，如何处理并发读写问题，以及如何统筹服务间的传输格式并不是一个简单的事情。

以本系统的帖子资源为例，常规的`limit-offset`分页方式的实现就很简单：查询时只要前端指定`page`和`page_size`，后端就可以转化为相应的`limit`与`offset`，进行查询。但是在本系统中该方式有着无法容忍的设计缺陷：

1. 并发状态下`offset`不准确的问题：由于本系统中帖子的资源是动态的，不像百度，谷歌等搜索引擎那样是隔一段时间统一添加资源，故而可能出现这种情况：
    1. 用户A发送了查询请求，拿到了第一页的10条数据；
    2. 之后系统中有10个用户分别发了10条帖子；
    3. 用户A此时浏览完了第一页，再去请求第二页数据时发现返回的数据和上次的数据一模一样。。。。。。
2. 由于本系统的查询功能不止有常规的，还有和搜索为服务通信的带有query的查询，而`elasticsearch`根据相关度进行排序，且对这种`offset-limit`的查询开销巨大（因为它的实现需要把前面的数据都加载到内存里扫一遍）

故而本系统使用了游标分页的方式进行处理，有关其介绍可以参考[这篇文章](https://juejin.cn/post/7306483885101039642)。前端对应的实现为无限滚动的形式（如知乎）

在本系统查询时，都添加一个`cursor`字段，查询结束时会返回一个`next_cursor`字段，表示下一次查询时的游标，当没有下一页时该字段缺省。

对于不同的服务，cursor的格式可能不一样，这是因为后端实现的逻辑不同，但这一点对前端是透明的，只需要当作普通的字符串存储下来，交给后端处理即可。

对于后端，会判断是否带有`query`字段来区分走正常的数据库查询还是搜索微服务，对于数据库查询，一般而言`cursor`的格式为资源的`id`等（表示创建的时间），而对于搜索服务，往往由双字段组成：先通过关键词匹配度排序，再通过id等进行排序。

同时，为了判断是否查到末尾，需要在查询时多查一条，进而构造相应的`next_cursor`。

### 7. 用户权限管理

在本系统中，仿照数据库产品的存取控制方法，实现了自己的权限系统。具体而言如下：

1. 对于本系统中的各个操作，如发帖，审核课程资料，创建课程/标签等等，都对应着一个权限；
2. 将部分权限的集合赋予角色，使得可以工厂化地创建用户权限，本系统目前有三种角色：普通用户/管理员/超级管理员；
3. 修改其他人的权限本身也是一种权限，该权限只有超级管理员拥有，且不可转让。

这样就实现了完整的权限系统，同时在主后端里还实现了权限中间件，可以工厂化地创建，实现对用户某一操作的权限的检验。

由于权限本身并没有太多，故而在系统设计时将权限表放到内存里以做加速。

### 8. ComfyUI工作流部署

我将本项目单独抽离出来，目前已在github上开源，其设计思路可以参考 [https://github.com/Poseidon-fan/ComfyUI-server](https://github.com/Poseidon-fan/ComfyUI-server)

## 主后端架构设计

后端采用gin框架与gorm框架，但我又对其进行了一层封装，以脚手架的方式进行开发。

系统中的文件顶层目录如下所示：

- main.go: 程序启动入口
- cmd: 存放系统级指令，如启动和接受回收资源等
- config: 存放配置信息以及系统初始化的代码
- global: 存放全局变量
- custom_error: 自定义错误类别
- model: 数据表模型定义的地方
- dao: 直接对数据库进行增删改查操作的代码
- service: 系统对外提供的所有服务
- api: 与前端进行数据交互
- router: 注册路由的地方
- middleware: 中间件
- permission: 权限系统的代码
- utils: 一些工具函数，如redis存取，发邮件等

系统与前端交互主要分四层：

| 层         | 作用                                                         |
| ---------- | ------------------------------------------------------------ |
| middleware | 到达系统路由之前的校验，如鉴权接口是否带上了token的信息，以及是否有相应的权限操作对应的数据 |
| api        | 直接与前端进行数据交互，向上返回数据，向下调用各个service    |
| service    | 接受相应的参数，执行系统操作，往往需要向下调用dao层接口或与其他服务通信 |
| dao        | 直接操作数据库的地方，只写最基础的，原子的增删改查操作       |

以上均在代码里进行了二次封装，以脚手架方式规范开发。